{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e12a149-d512-4680-9f86-8f6557adc213",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7b81b8a-f59d-4542-8acb-12cc95e7fe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "343ab3d1-6731-4ec0-abbc-907cb6cb6d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a9ef158-b932-4b3e-99ec-972472b7190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download NLTK data (if not already downloaded)\n",
    "#nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c507073-6391-47a3-9fdb-4c804407adc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample corpus\n",
    "sentences = [\n",
    "    \"NLP helps computers understand and interpret human language\",\n",
    "    \"NLP tasks include text classification, machine translation, and sentiment analysis\",\n",
    "    \"NLP models are trained on large datasets of text to learn patterns and relationships.\",\n",
    "    \"NLP applications are used in various fields, such as customer service, healthcare, and marketing.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "674196fc-96fa-4a3f-a5eb-a5bdf27734fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['nlp',\n",
       "  'helps',\n",
       "  'computers',\n",
       "  'understand',\n",
       "  'and',\n",
       "  'interpret',\n",
       "  'human',\n",
       "  'language'],\n",
       " ['nlp',\n",
       "  'tasks',\n",
       "  'include',\n",
       "  'text',\n",
       "  'classification',\n",
       "  ',',\n",
       "  'machine',\n",
       "  'translation',\n",
       "  ',',\n",
       "  'and',\n",
       "  'sentiment',\n",
       "  'analysis'],\n",
       " ['nlp',\n",
       "  'models',\n",
       "  'are',\n",
       "  'trained',\n",
       "  'on',\n",
       "  'large',\n",
       "  'datasets',\n",
       "  'of',\n",
       "  'text',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'patterns',\n",
       "  'and',\n",
       "  'relationships',\n",
       "  '.'],\n",
       " ['nlp',\n",
       "  'applications',\n",
       "  'are',\n",
       "  'used',\n",
       "  'in',\n",
       "  'various',\n",
       "  'fields',\n",
       "  ',',\n",
       "  'such',\n",
       "  'as',\n",
       "  'customer',\n",
       "  'service',\n",
       "  ',',\n",
       "  'healthcare',\n",
       "  ',',\n",
       "  'and',\n",
       "  'marketing',\n",
       "  '.']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the sentences\n",
    "tokenized_sentences = [word_tokenize(i.lower()) for i in sentences]\n",
    "tokenized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71733f29-d4ec-4b28-9fda-9e0c62e5d0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c5167ff-405c-41a7-bab1-8fd85fcd1a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nlp',\n",
       " 'tasks',\n",
       " 'include',\n",
       " 'text',\n",
       " 'classification',\n",
       " ',',\n",
       " 'machine',\n",
       " 'translation',\n",
       " ',',\n",
       " 'and',\n",
       " 'sentiment',\n",
       " 'analysis']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b47cea3-966e-4a4f-aa9d-93aa92addc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Word2Vec model using skip gram\n",
    "model = Word2Vec(sentences=tokenized_sentences, \n",
    "                 vector_size=100, \n",
    "                 window=5, \n",
    "                 min_count=1, \n",
    "                 workers=4,\n",
    "                 sg=0,compute_loss=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1459f0-8b28-48c9-b491-8fc39c5cf997",
   "metadata": {},
   "source": [
    "1. vector_size=100 defines the number of dimensions for each word's embedding vector.\n",
    "2. window=5 specifies how many surrounding words the model will consider when training.\n",
    "3. min_count=1 includes all words in the vocabulary, even those appearing only once.\n",
    "4. workers=4,  The training will be faster because 4 cores can work simultaneously, processing multiple words and contexts in parallel.\n",
    "5. sg=0: CBOW (Continuous Bag of Words), sg=1: Skip-Gram (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b222aeeb-b083-41cf-a7b0-bdba066ecd76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 530)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.train(tokenized_sentences, total_examples=len(tokenized_sentences), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3382df00-90b7-4a52-a1c5-414dc7fadebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('used', 0.1896437555551529),\n",
       " ('fields', 0.1893627792596817),\n",
       " ('human', 0.16177138686180115),\n",
       " ('helps', 0.16105271875858307),\n",
       " ('language', 0.13932116329669952)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find similar words\n",
    "similar_words = model.wv.most_similar('nlp', topn=5)\n",
    "similar_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c09429b2-a3e8-403a-88ac-4c5f7863f754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 words similar to 'nlp':\n",
      "used: 0.1896\n",
      "fields: 0.1894\n",
      "human: 0.1618\n",
      "helps: 0.1611\n",
      "language: 0.1393\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 5 words similar to 'nlp':\")\n",
    "for similar_word, score in similar_words:\n",
    "    print(f\"{similar_word}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eed932c3-bc56-4bc3-b10a-95a2edb8f231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nearest word to 'nlp': used\n"
     ]
    }
   ],
   "source": [
    "# Find the nearest word (the most similar word)\n",
    "nearest_word = similar_words[0][0]  # The first word in the list is the nearest\n",
    "print(f\"\\nNearest word to 'nlp': {nearest_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45262654-4ca8-4652-b708-c45893c73e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49b8660-76f9-4134-89e2-d69fbc991787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c245130d-2849-4cd0-99e0-9c797b3c3e38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573f85ee-ce25-4f03-a5cb-ca74586db383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b160cf3f-06b3-4d54-b96a-b1cddaddc90e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
